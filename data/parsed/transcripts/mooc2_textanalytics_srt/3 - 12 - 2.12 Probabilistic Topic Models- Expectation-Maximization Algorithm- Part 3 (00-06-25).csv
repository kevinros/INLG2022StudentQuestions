name,id,from,to,text
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,1,7.553,12.636,_So, I just showed you that empirically the likelihood will converge, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,2,12.636,17.041,but theoretically it can also be proved that EM algorithm will 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,3,17.041,19.295,converge to a local maximum. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,4,19.295,24.925,So here's just an illustration of what happened and a detailed explanation. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,5,24.925,29.613,_This required more knowledge about that, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,6,29.613,36.91,_some of that inequalities, that we haven't really covered yet. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,7,39.38,45.04,_So here what you see is on the X dimension, we have a c0 value. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,8,45.04,46.799,This is a parameter that we have. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,9,46.799,49.714,On the y axis we see the likelihood function. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,10,49.714,57.171,_So this curve is the original likelihood function, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,11,57.171,64.11,and this is the one that we hope to maximize. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,12,64.11,66.63,And we hope to find a c0 value at this point to maximize this. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,13,66.63,71.48,But in the case of Mitsumoto we can not easily find an analytic solution 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,14,71.48,72.47,to the problem. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,15,72.47,74.69800000000001,_So, we have to resolve the numerical errors, and _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,16,74.69800000000001,76.457,the EM algorithm is such an algorithm. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,17,76.457,77.85,It's a Hill-Climb algorithm. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,18,77.85,82.49,That would mean you start with some random guess. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,19,82.49,86.26,_Let's say you start from here, that's your starting point. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,20,86.26,92.09,And then you try to improve this by moving this to 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,21,92.09,95.42,another point where you can have a higher likelihood. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,22,95.42,97.63,So that's the ideal hill climbing. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,23,97.63,103.03,_And in the EM algorithm, the way we achieve this is to do two things. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,24,103.03,106.94,_First, we'll fix a lower bound of likelihood function. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,25,106.94,108.628,So this is the lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,26,108.628,109.128,See here. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,27,111.00999999999999,117.56,_And once we fit the lower bound, we can then maximize the lower bound. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,28,117.56,119.42,_And of course, the reason why this works, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,29,119.42,122.85,is because the lower bound is much easier to optimize. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,30,122.85,125.78,So we know our current guess is here. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,31,125.78,131.53,_And by maximizing the lower bound, we'll move this point to the top. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,32,131.53,132.03,To here. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,33,133.3,134.65,Right? 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,34,134.65,140.15,_And we can then map to the original likelihood function, we find this point. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,35,140.15,145.6,_Because it's a lower bound, we are guaranteed to improve this guess, right? _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,36,145.6,150.57,Because we improve our lower bound and then the original likelihood 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,37,150.57,155.04,curve which is above this lower bound will definitely be improved as well. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,38,156.31,159.09,So we already know it's improving the lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,39,159.09,162.44,_So we definitely improve this original likelihood function, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,40,162.44,167.253,which is above this lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,41,167.253,169.77,_So, in our example, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,42,169.77,173.52,the current guess is parameter value given by the current generation. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,43,173.52,177.66,And then the next guess is the re-estimated parameter values. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,44,177.66,181.11,From this illustration you can see the next guess 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,45,181.11,183.62,is always better than the current guess. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,46,183.62,186.93,_Unless it has reached the maximum, where it will be stuck there. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,47,186.93,188.008,So the two would be equal. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,48,188.008,192.821,_So, the E-step is basically _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,49,192.821,197.65,to compute this lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,50,197.65,202.061,We don't directly just compute this likelihood function but 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,51,202.061,205.452,we compute the length of the variable values and 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,52,205.452,208.99,these are basically a part of this lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,53,208.99,211.15,This helps determine the lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,54,211.15,214.46,The M-step on the other hand is to maximize the lower bound. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,55,214.46,217.48,It allows us to move parameters to a new point. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,56,217.48,221.46,And that's why EM algorithm is guaranteed to converge to a local maximum. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,57,222.49,226.72,_Now, as you can imagine, when we have many local maxima, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,58,226.72,230.1,we also have to repeat the EM algorithm multiple times. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,59,230.1,234.34,In order to figure out which one is the actual global maximum. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,60,234.34,239.07,And this actually in general is a difficult problem in numeral optimization. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,61,239.07,242.689,_So here for example had we started from here, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,62,242.689,246.223,then we gradually just climb up to this top. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,63,246.223,251.227,_So, that's not optimal, and we'd like to climb up all the way to here, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,64,251.227,256.575,so the only way to climb up to this gear is to start from somewhere here or here. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,65,256.575,262.767,_So, in the EM algorithm, we generally would have to start from different points _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,66,262.767,267.88,or have some other way to determine a good initial starting point. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,67,269.84,274.32,To summarize in this lecture we introduced the EM algorithm. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,68,274.32,278.683,This is a general algorithm for computing maximum maximum likelihood estimate of all 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,69,278.683,282.153,_kinds of models, so not just for our simple model. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,70,282.153,286.468,_And it's a hill-climbing algorithm, so it can only converge to a local maximum and _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,71,286.468,288.25,it will depend on initial points. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,72,289.77,295.414,The general idea is that we will have two steps to improve the estimate of. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,73,295.414,300.27,In the E-step we roughly [INAUDIBLE] how many there are by predicting values 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,74,300.27,305.56,of useful hidden variables that we would use to simplify the estimation. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,75,305.56,310.056,_In our case, this is the distribution that has been used to generate the word. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,76,310.056,315.75,In the M-step then we would exploit such augmented data which would make 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,77,315.75,320.79,_it easier to estimate the distribution, to improve the estimate of parameters. _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,78,320.79,324.86,Here improve is guaranteed in terms of the likelihood function. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,79,324.86,330.24,Note that it's not necessary that we will have a stable convergence of 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,80,330.24,335.26,parameter value even though the likelihood function is ensured to increase. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,81,335.26,340.37,There are some properties that have to be satisfied in order for the parameters 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,82,340.37,344.64,also to convert into some stable value. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,83,347.5,350.79,Now here data augmentation is done probabilistically. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,84,350.79,351.36,_That means, _
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,85,351.36,354.83,we're not going to just say exactly what's the value of a hidden variable. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,86,354.83,359.39,But we're going to have a probability distribution over the possible values of 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,87,359.39,361.14,these hidden variables. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,88,361.14,365.99,So this causes a split of counts of events probabilistically. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,89,367.43,372.783,And in our case we'll split the word counts between the two distributions. 
3 - 12 - 2.12 Probabilistic Topic Models- Expectation-Maximization Algorithm- Part 3 (00-06-25).srt,90,372.783,382.783,[MUSIC] 
