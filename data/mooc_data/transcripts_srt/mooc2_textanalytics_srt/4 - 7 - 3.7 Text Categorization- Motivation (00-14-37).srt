1
00:00:00,192 --> 00:00:03,512
[SOUND]

2
00:00:06,614 --> 00:00:09,660
This lecture is about text categorization.

3
00:00:11,360 --> 00:00:15,320
In this lecture, we're going to
talk about text categorization.

4
00:00:16,390 --> 00:00:21,320
This is a very important technique for
text data mining and analytics.

5
00:00:22,470 --> 00:00:27,035
It is relevant to discovery
of various different kinds of

6
00:00:27,035 --> 00:00:29,134
knowledge as shown here.

7
00:00:29,134 --> 00:00:33,380
First, it's related to topic mining and
analysis.

8
00:00:33,380 --> 00:00:36,060
And, that's because it has to do with

9
00:00:36,060 --> 00:00:40,970
analyzing text to data based
on some predefined topics.

10
00:00:40,970 --> 00:00:46,239
Secondly, it's also related to
opinion mining and sentiment analysis,

11
00:00:46,239 --> 00:00:51,941
which has to do with discovery knowledge
about the observer, the human sensor.

12
00:00:51,941 --> 00:00:56,301
Because we can categorize the authors,
for example,

13
00:00:56,301 --> 00:01:01,813
based on the content of the articles
that they have written, right?

14
00:01:01,813 --> 00:01:06,611
We can, in general,
categorize the observer

15
00:01:06,611 --> 00:01:10,800
based on the content that they produce.

16
00:01:12,300 --> 00:01:16,720
Finally, it's also related
to text-based prediction.

17
00:01:16,720 --> 00:01:21,760
Because, we can often use text
categorization techniques to predict some

18
00:01:21,760 --> 00:01:26,180
variables in the real world that
are only remotely related to text data.

19
00:01:27,230 --> 00:01:32,490
And so, this is a very important
technique for text to data mining.

20
00:01:34,820 --> 00:01:37,860
This is the overall plan for
covering the topic.

21
00:01:37,860 --> 00:01:40,750
First, we're going to talk about
what is text categorization and

22
00:01:40,750 --> 00:01:44,510
why we're interested in
doing that in this lecture?

23
00:01:44,510 --> 00:01:47,920
And now, we're going to talk about
how to do text categorization for

24
00:01:47,920 --> 00:01:50,780
how to evaluate
the categorization results.

25
00:01:50,780 --> 00:01:56,140
So, the problem of text
categorization is defined as follows.

26
00:01:56,140 --> 00:02:03,461
We're given a set of predefined categories
possibly forming a hierarchy or so.

27
00:02:03,461 --> 00:02:07,462
And often,
also a set of training examples or

28
00:02:07,462 --> 00:02:12,519
training set of labeled text
objects which means the text

29
00:02:12,519 --> 00:02:17,810
objects have already been
enabled with known categories.

30
00:02:17,810 --> 00:02:23,040
And then, the task is to classify
any text object into one or

31
00:02:23,040 --> 00:02:26,320
more of these predefined categories.

32
00:02:26,320 --> 00:02:29,139
So, the picture on this
slide shows what happens.

33
00:02:30,270 --> 00:02:32,120
When we do text categorization,

34
00:02:32,120 --> 00:02:37,630
we have a lot of text objects to be
processed by a categorization system and

35
00:02:37,630 --> 00:02:43,820
the system will, in general,
assign categories through these documents.

36
00:02:43,820 --> 00:02:49,110
As shown on the right and
the categorization results,

37
00:02:49,110 --> 00:02:54,280
and we often assume the availability
of training examples and

38
00:02:54,280 --> 00:02:59,060
these are the documents that
are tag with known categories.

39
00:02:59,060 --> 00:03:01,660
And these examples are very important for

40
00:03:01,660 --> 00:03:06,110
helping the system to learn
patterns in different categories.

41
00:03:06,110 --> 00:03:10,180
And, this would further help
the system then know how to recognize

42
00:03:11,280 --> 00:03:16,560
the categories of new text
objects that it has not seen.

43
00:03:16,560 --> 00:03:20,950
So, here are some specific
examples of text categorization.

44
00:03:20,950 --> 00:03:26,140
And in fact, there are many examples,
here are just a few.

45
00:03:27,230 --> 00:03:33,000
So first, text objects can vary,
so we can categorize a document,

46
00:03:33,000 --> 00:03:36,730
or a passage, or a sentence,
or collections of text.

47
00:03:36,730 --> 00:03:41,400
As in the case of clustering, the units
to be analyzed can vary a lot, so

48
00:03:41,400 --> 00:03:44,090
this creates a lot of possibilities.

49
00:03:44,090 --> 00:03:46,690
Secondly, categories can also vary.

50
00:03:46,690 --> 00:03:49,880
Allocate in general,
there's two major kinds of categories.

51
00:03:49,880 --> 00:03:51,560
One is internal categories.

52
00:03:51,560 --> 00:03:55,890
These are categories that
categorize content of text object.

53
00:03:55,890 --> 00:04:00,850
For example, topic categories or
sentiment categories and

54
00:04:00,850 --> 00:04:04,810
they generally have to do with
the content of the text objects

55
00:04:04,810 --> 00:04:06,930
throughout the categorization
of the content.

56
00:04:08,210 --> 00:04:13,430
The other kind is external categories
that can characterize an entity

57
00:04:13,430 --> 00:04:16,120
associated with the text object.

58
00:04:16,120 --> 00:04:17,630
For example,

59
00:04:17,630 --> 00:04:22,810
authors are entities associated
with the content that they produce.

60
00:04:22,810 --> 00:04:28,340
And so, we can use their content in
determining which author has written,

61
00:04:28,340 --> 00:04:31,670
which part, for example, and
that's called author attribution.

62
00:04:33,540 --> 00:04:38,048
Or, we can have any
other mininal categories

63
00:04:38,048 --> 00:04:43,147
associate with text data
as long as there is minimal

64
00:04:43,147 --> 00:04:47,788
connection between the entity and
text data.

65
00:04:47,788 --> 00:04:54,025
For example, we might collect a lot
of reviews about a restaurant or

66
00:04:54,025 --> 00:04:58,073
a lot of reviews about a product,
and then,

67
00:04:58,073 --> 00:05:04,770
this text data can help us infer
properties of a product or a restaurant.

68
00:05:04,770 --> 00:05:07,770
In that case, we can treat this
as a categorization problem.

69
00:05:07,770 --> 00:05:09,921
We can categorize restaurants or

70
00:05:09,921 --> 00:05:13,924
categorize products based on
their corresponding reviews.

71
00:05:13,924 --> 00:05:17,245
So, this is an example for
external category.

72
00:05:17,245 --> 00:05:20,400
Here are some specific
examples of the applications.

73
00:05:20,400 --> 00:05:25,110
News categorization is very
common as being started a lot.

74
00:05:25,110 --> 00:05:30,009
News agencies would like
to assign predefined

75
00:05:30,009 --> 00:05:35,672
categories to categorize
news generated everyday.

76
00:05:35,672 --> 00:05:39,824
And, these virtual article
categorizations are not important aspect.

77
00:05:39,824 --> 00:05:43,650
For example, in the biomedical domain,
there's MeSH annotations.

78
00:05:43,650 --> 00:05:47,930
MeSH stands for Medical Subject Heading,
and this is ontology of terms,

79
00:05:49,090 --> 00:05:52,490
characterize content of
literature articles in detail.

80
00:05:54,590 --> 00:05:59,860
Another example of application is spam
email detection or filtering, right?

81
00:05:59,860 --> 00:06:04,940
So, we often have a spam filter

82
00:06:04,940 --> 00:06:10,260
to help us distinguish spams
from legitimate emails and

83
00:06:10,260 --> 00:06:13,000
this is clearly a binary
classification problem.

84
00:06:14,500 --> 00:06:18,460
Sentiment categorization of
product reviews or tweets is yet

85
00:06:18,460 --> 00:06:23,120
another kind of applications where we
can categorize, comparing to positive or

86
00:06:23,120 --> 00:06:26,380
negative or positive and
negative or neutral.

87
00:06:27,460 --> 00:06:32,820
So, you can have send them to categories,
assign the two text content.

88
00:06:35,520 --> 00:06:39,480
Another application is automatic
email routing or sorting, so,

89
00:06:39,480 --> 00:06:43,750
you might want to automatically sort your
emails into different folders and that's

90
00:06:43,750 --> 00:06:47,320
one application of text categorization
where each folder is a category.

91
00:06:48,370 --> 00:06:52,580
The results are another important kind
of applications of routing emails

92
00:06:52,580 --> 00:06:55,910
to the right person to handle,
so, in helpdesk,

93
00:06:55,910 --> 00:07:01,890
email messaging is generally routed
to a particular person to handle.

94
00:07:01,890 --> 00:07:05,820
Different people tend to handle
different kinds of requests.

95
00:07:05,820 --> 00:07:11,220
And in many cases, a person would manually
assign the messages to the right people.

96
00:07:11,220 --> 00:07:15,231
But, if you can imagine,
you can't be able to automatically

97
00:07:15,231 --> 00:07:18,794
text categorization system
to help routing request.

98
00:07:18,794 --> 00:07:24,969
And, this is a class file, the incoming
request in the one of the categories

99
00:07:24,969 --> 00:07:31,265
where each category actually corresponds
to a person to handle the request.

100
00:07:31,265 --> 00:07:35,975
And finally, author attribution, as I just
mentioned, is yet another application, and

101
00:07:35,975 --> 00:07:39,759
it's another example of using text
to actually infer properties of

102
00:07:41,480 --> 00:07:42,960
some other entities.

103
00:07:42,960 --> 00:07:46,890
And, there are also many variants
of the problem formulation.

104
00:07:46,890 --> 00:07:50,980
And so, first, we have the simplest case,
which is a binary categorization,

105
00:07:50,980 --> 00:07:52,990
where there are only two categories.

106
00:07:52,990 --> 00:07:57,660
And, there are many examples like that,
information retrieval or search engine.

107
00:07:59,040 --> 00:08:03,600
Applications with one distinguishing
relevant documents from non-relevant

108
00:08:03,600 --> 00:08:04,940
documents for a particular query.

109
00:08:06,040 --> 00:08:12,330
Spam filtering just distinguishing spams
from non-spams, so, also two categories.

110
00:08:12,330 --> 00:08:16,800
Sometimes, classifications of
opinions can be in two categories,

111
00:08:16,800 --> 00:08:17,800
positive and a negative.

112
00:08:19,120 --> 00:08:22,650
A more general case would be K-category
categorization and there are also

113
00:08:22,650 --> 00:08:26,755
many applications like that,
there could be more than two categories.

114
00:08:26,755 --> 00:08:30,155
So, topic categorization is often
such an example where you can have

115
00:08:30,155 --> 00:08:31,935
multiple topics.

116
00:08:31,935 --> 00:08:36,205
Email routing would be another example
when you may have multiple folders or

117
00:08:36,205 --> 00:08:39,322
if you route the email to
the right person to handle it,

118
00:08:39,322 --> 00:08:44,550
then there are multiple
people to classify.

119
00:08:44,550 --> 00:08:48,212
So, in all these cases, there are more
than two kinds of categories.

120
00:08:49,272 --> 00:08:52,382
Another variation is to have
hierarchical categorization

121
00:08:52,382 --> 00:08:54,442
where categories form a hierarchy.

122
00:08:54,442 --> 00:08:56,602
Again, topical hierarchy is very common.

123
00:08:58,232 --> 00:09:00,742
Yet another variation is
joint categorization.

124
00:09:00,742 --> 00:09:04,550
That's when you have multiple
categorization tasks that are related and

125
00:09:04,550 --> 00:09:08,150
then you hope to kind of
join the categorization.

126
00:09:08,150 --> 00:09:13,340
Further leverage the dependency of
these tasks to improve accuracy for

127
00:09:13,340 --> 00:09:15,250
each individual task.

128
00:09:15,250 --> 00:09:19,870
Among all these binary categorizations
is most fundamental and

129
00:09:19,870 --> 00:09:25,170
part of it also is because it's simple and
probably it's because

130
00:09:25,170 --> 00:09:31,000
it can actually be used to perform
all the other categorization tasks.

131
00:09:31,000 --> 00:09:34,839
For example, a K-category
categorization task can be actually

132
00:09:34,839 --> 00:09:38,665
performed by using binary categorization.

133
00:09:40,075 --> 00:09:43,405
Basically, we can look at
each category separately and

134
00:09:43,405 --> 00:09:49,385
then the binary categorization problem
is whether object is in this category or

135
00:09:49,385 --> 00:09:52,005
not, meaning in other categories.

136
00:09:53,485 --> 00:09:59,820
And, the hierarchical categorization
can also be done by progressively

137
00:09:59,820 --> 00:10:04,300
doing flat categorization at each level.

138
00:10:04,300 --> 00:10:07,000
So, we have, first, we categorize
all the objects into, let's say,

139
00:10:07,000 --> 00:10:09,140
a small number of high-level categories,

140
00:10:09,140 --> 00:10:13,740
and inside each category, we have further
categorized to sub-categories, etc.

141
00:10:15,000 --> 00:10:16,728
So, why is text categorization important?

142
00:10:16,728 --> 00:10:21,464
Well, I already showed that you,
several applications but, in general,

143
00:10:21,464 --> 00:10:23,244
there are several reasons.

144
00:10:23,244 --> 00:10:28,891
One is text categorization helps enrich
text representation and that's to achieve

145
00:10:28,891 --> 00:10:34,970
more understanding of text data that's
all it was useful for text analysis.

146
00:10:34,970 --> 00:10:38,738
So, now with categorization text can
be represented in multiple levels.

147
00:10:38,738 --> 00:10:47,310
The keyword conditions that's often
used for a lot text processing tasks.

148
00:10:47,310 --> 00:10:52,455
But we can now also add categories and
they provide two levels of transition.

149
00:10:55,485 --> 00:11:00,085
Semantic categories assigned can also
be directly or indirectly useful for

150
00:11:00,085 --> 00:11:01,145
application.

151
00:11:01,145 --> 00:11:07,869
So, for example, semantic categories
could be already very useful or

152
00:11:07,869 --> 00:11:12,248
other attribution might
be directly useful.

153
00:11:12,248 --> 00:11:18,118
Another example is when semantic
categories can facilitate aggregation

154
00:11:18,118 --> 00:11:24,660
of text content and this is another case
of applications of text categorization.

155
00:11:25,950 --> 00:11:30,940
For example, if we want to know
the overall opinions about a product, we

156
00:11:32,010 --> 00:11:37,830
could first categorize the opinions
in each individual view

157
00:11:37,830 --> 00:11:42,730
as positive or negative and then, that
would allow us to easy to aggregate all

158
00:11:42,730 --> 00:11:47,810
the sentiment, and it would tell us about

159
00:11:47,810 --> 00:11:52,680
the 70% of the views are positive and
30% are negative, etc.

160
00:11:53,810 --> 00:11:56,865
So, without doing categorization,

161
00:11:56,865 --> 00:12:02,402
it will be much harder to aggregate
such opinions to provide a concise

162
00:12:02,402 --> 00:12:07,468
way of coding text in some sense
based on all of the vocabulary.

163
00:12:07,468 --> 00:12:13,640
And, sometimes you may see in some
applications, text with categorizations

164
00:12:13,640 --> 00:12:18,704
called a text coded,
encoded with some control of vocabulary.

165
00:12:18,704 --> 00:12:22,316
The second kind of reasons is to use text

166
00:12:22,316 --> 00:12:27,024
categorization to infer
properties of entities,

167
00:12:27,024 --> 00:12:31,950
and text categories allows
us to infer the properties

168
00:12:31,950 --> 00:12:36,950
of such entities that
are associate with text data.

169
00:12:36,950 --> 00:12:41,140
So, this means we can
use text categorization

170
00:12:41,140 --> 00:12:44,090
to discover knowledge about the world.

171
00:12:44,090 --> 00:12:48,370
In general, as long as we can associate
the entity with text of data,

172
00:12:48,370 --> 00:12:53,600
we can always the text of data to help
categorize the corresponding entities.

173
00:12:53,600 --> 00:12:54,502
So, it's used for

174
00:12:54,502 --> 00:12:59,380
single information network that will
connect the other entities with text data.

175
00:12:59,380 --> 00:13:03,750
The obvious entities that can be
directly connected are authors.

176
00:13:03,750 --> 00:13:08,340
But, you can also imagine the author's
affiliations or the author's age and

177
00:13:08,340 --> 00:13:14,090
other things can be actually
connected to text data indirectly.

178
00:13:14,090 --> 00:13:18,860
Once we have made the connection, then we
can make a prediction about those values.

179
00:13:18,860 --> 00:13:23,520
So, this is a general way to allow
us to use text mining through, so

180
00:13:23,520 --> 00:13:26,890
the text categorization to discover
knowledge about the world.

181
00:13:26,890 --> 00:13:32,330
Very useful, especially in big text
data analytics where we are often

182
00:13:32,330 --> 00:13:38,150
just using text data as extra sets
of data extracted from humans

183
00:13:38,150 --> 00:13:43,930
to infer certain decision factors
often together with non-textual data.

184
00:13:43,930 --> 00:13:45,710
Specifically with text, for example,

185
00:13:45,710 --> 00:13:49,220
we can also think of examples of
inferring properties of entities.

186
00:13:49,220 --> 00:13:53,190
For example, discovery of
non-native speakers of a language.

187
00:13:53,190 --> 00:13:59,460
And, this can be done by categorizing
the content of speakers.

188
00:14:00,680 --> 00:14:05,566
Another example is to predict the party
affiliation of a politician based

189
00:14:05,566 --> 00:14:07,314
on the political speech.

190
00:14:07,314 --> 00:14:11,967
And, this is again an example
of using text data to infer

191
00:14:11,967 --> 00:14:15,146
some knowledge about the real world.

192
00:14:15,146 --> 00:14:19,265
In nature,
the problems are all the same, and

193
00:14:19,265 --> 00:14:24,980
that's as we defined and
it's a text categorization problem.

194
00:14:24,980 --> 00:14:34,980
[MUSIC]