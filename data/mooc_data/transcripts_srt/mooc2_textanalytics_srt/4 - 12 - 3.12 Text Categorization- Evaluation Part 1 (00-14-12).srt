1
00:00:00,025 --> 00:00:04,845
[SOUND] This lecture is about

2
00:00:04,845 --> 00:00:12,188
the Evaluation of Text Categorization.

3
00:00:12,188 --> 00:00:15,930
So we've talked about many different
methods for text categorization.

4
00:00:15,930 --> 00:00:17,900
But how do you know which
method works better?

5
00:00:19,080 --> 00:00:20,610
And for a particular application,

6
00:00:20,610 --> 00:00:25,880
how do you know this is the best
way of solving your problem?

7
00:00:25,880 --> 00:00:27,670
To understand these, we have to

8
00:00:29,270 --> 00:00:34,870
how to we have to know how to
evaluate categorization results.

9
00:00:34,870 --> 00:00:37,320
So first some general thoughts
about the evaluation.

10
00:00:38,650 --> 00:00:44,530
In general, for evaluation of this kind of
empirical tasks such as categorization,

11
00:00:44,530 --> 00:00:49,380
we use methodology that
was developed in 1960s by

12
00:00:49,380 --> 00:00:51,620
information retrieval researchers.

13
00:00:51,620 --> 00:00:53,380
Called a Cranfield Evaluation Methodology.

14
00:00:53,380 --> 00:00:58,100
The basic idea is to have
humans create test correction,

15
00:00:59,880 --> 00:01:04,550
where, we already know, every document
is tagged with the desired categories.

16
00:01:04,550 --> 00:01:08,680
Or, in the case of search, for which
query, which documents that should have

17
00:01:08,680 --> 00:01:12,080
been retrieved, and
this is called, a ground truth.

18
00:01:12,080 --> 00:01:14,740
Now, with this ground
truth test correction,

19
00:01:14,740 --> 00:01:19,950
we can then reuse the collection to
test the many different systems and

20
00:01:19,950 --> 00:01:21,900
then compare different systems.

21
00:01:21,900 --> 00:01:26,290
We can also turn off some components in
the system to see what's going to happen.

22
00:01:26,290 --> 00:01:34,690
Basically it provides a way to do control
experiments to compare different methods.

23
00:01:36,570 --> 00:01:39,910
So this methodology has
been virtually used for

24
00:01:39,910 --> 00:01:44,450
all the tasks that involve
empirically defined problems.

25
00:01:45,950 --> 00:01:50,810
So in our case, then, we are going to
compare our systems categorization

26
00:01:50,810 --> 00:01:55,530
results with the categorization,
ground truth, created by humans.

27
00:01:56,730 --> 00:01:59,569
And we're going to compare
our systems decisions,

28
00:02:00,820 --> 00:02:04,540
which documents should get
which category with what

29
00:02:06,120 --> 00:02:09,620
categories have been assigned
to those documents by humans.

30
00:02:09,620 --> 00:02:14,930
And we want to quantify
the similarity of these decisions or

31
00:02:14,930 --> 00:02:19,200
equivalently, to measure the difference
between the system output and

32
00:02:19,200 --> 00:02:23,670
the desired ideal output
generated by the humans.

33
00:02:25,020 --> 00:02:29,040
So obviously, the highest similarity
is the better results are.

34
00:02:30,100 --> 00:02:33,800
The similarity could be
measured in different ways.

35
00:02:33,800 --> 00:02:35,760
And that would lead to different measures.

36
00:02:35,760 --> 00:02:40,870
And sometimes it's desirable also to match
the similarity from different perspectives

37
00:02:40,870 --> 00:02:44,660
just to have a better understanding
of the results in detail.

38
00:02:44,660 --> 00:02:49,370
For example, we might be also interested
in knowing which category performs

39
00:02:49,370 --> 00:02:52,850
better and which which category
is easy to categorize, etc.

40
00:02:52,850 --> 00:02:58,890
In general,
different categorization mistakes

41
00:02:58,890 --> 00:03:03,570
however, have different costs for
specific applications.

42
00:03:03,570 --> 00:03:06,710
So some areas might be
more serious than others.

43
00:03:06,710 --> 00:03:12,080
So ideally, we would like to model
such differences, but if you read

44
00:03:12,080 --> 00:03:16,200
many papers in categorization you will
see that they don't generally do that.

45
00:03:16,200 --> 00:03:22,027
Instead, they will use a simplified
measure and that's because it's

46
00:03:22,027 --> 00:03:28,144
often okay not to consider such a cost
variation when we compare methods and

47
00:03:28,144 --> 00:03:34,478
when we are interested in knowing
the relative difference of these methods.

48
00:03:34,478 --> 00:03:39,616
So it's okay to introduce some bias,
as long as the bias is not already with

49
00:03:39,616 --> 00:03:44,677
a particular method and then we should
expect the more effective method to

50
00:03:44,677 --> 00:03:50,410
perform better than a less effective one,
even though the measure is not perfect.

51
00:03:53,110 --> 00:03:56,620
So the first measure that we'll introduce
is called classification accuracy and

52
00:03:56,620 --> 00:04:00,370
this is a basic into measure
the percentage of correct decisions.

53
00:04:00,370 --> 00:04:04,990
So here you see that there
are categories denoted by c1

54
00:04:04,990 --> 00:04:10,620
through ck and there are n documents,
denoted by d1 through d N.

55
00:04:10,620 --> 00:04:12,470
And for each pair of category and

56
00:04:12,470 --> 00:04:14,920
the document,
we can then look at the situation.

57
00:04:16,710 --> 00:04:21,060
And see if the system has
said yes to this pair,

58
00:04:21,060 --> 00:04:23,660
basically has assigned this
category to this document.

59
00:04:23,660 --> 00:04:29,060
Or no, so this is denoted by Y or M,
that's the systems of the decision.

60
00:04:29,060 --> 00:04:34,290
And similarly, we can look at the human's
decisions also, if the human has assigned

61
00:04:34,290 --> 00:04:37,810
a category to the document of that
there will be a plus sign here.

62
00:04:37,810 --> 00:04:40,660
That just means that a human.

63
00:04:40,660 --> 00:04:46,360
We think of this assignment is correct and
incorrect then it's a minus.

64
00:04:46,360 --> 00:04:53,708
So we'll see all combinations of this Ns,
yes and nos, minus and pluses.

65
00:04:53,708 --> 00:04:56,178
There are four combinations in total.

66
00:04:56,178 --> 00:05:01,041
And two of them are correct, and
that's when we have y(+) or n(-),

67
00:05:01,041 --> 00:05:04,570
and then there are also
two kinds of errors.

68
00:05:04,570 --> 00:05:07,640
So the measure of classification
accuracy is simply to count

69
00:05:07,640 --> 00:05:10,310
how many of these decisions are correct.

70
00:05:10,310 --> 00:05:14,050
And normalize that by the total
number of decisions we have made.

71
00:05:14,050 --> 00:05:19,180
So, we know that the total number
of decisions is n, multiplied by k.

72
00:05:20,310 --> 00:05:25,090
And, the number of correct decisions
are basically of two kinds.

73
00:05:25,090 --> 00:05:26,580
One is y plusses.

74
00:05:26,580 --> 00:05:28,300
And the other is n minus this n.

75
00:05:28,300 --> 00:05:30,720
We just put together the count.

76
00:05:30,720 --> 00:05:34,800
Now, this is a very convenient
measure that will give us one number

77
00:05:34,800 --> 00:05:38,140
to characterize performance of a method.

78
00:05:38,140 --> 00:05:39,670
And the higher, the better, of course.

79
00:05:41,190 --> 00:05:44,530
But the method also has some problems.

80
00:05:44,530 --> 00:05:48,800
First it has treated all
the decisions equally.

81
00:05:48,800 --> 00:05:53,310
But in reality, some decision errors
are more serious than others.

82
00:05:53,310 --> 00:05:56,900
For example, it may be more important to
get the decisions right on some documents,

83
00:05:56,900 --> 00:05:57,490
than others.

84
00:05:58,950 --> 00:06:02,200
Or maybe, more important to get
the decisions right on some categories,

85
00:06:02,200 --> 00:06:05,080
than others, and this would call for

86
00:06:05,080 --> 00:06:10,978
some detailed evaluation of this
results to understand the strands and

87
00:06:12,410 --> 00:06:18,440
of different methods, and to understand
the performance of these methods.

88
00:06:18,440 --> 00:06:22,897
In detail in a per category or

89
00:06:22,897 --> 00:06:26,248
per document basis.

90
00:06:26,248 --> 00:06:30,545
One example that shows clearly
the decision errors are having different

91
00:06:30,545 --> 00:06:35,337
causes is spam filtering that could be
retrieved as two category categorization

92
00:06:35,337 --> 00:06:35,980
problem.

93
00:06:36,980 --> 00:06:42,360
Missing a legitimate email result,
is one type of error.

94
00:06:42,360 --> 00:06:47,050
But letting spam to come into your
folder is another type of error.

95
00:06:47,050 --> 00:06:50,500
The two types of errors
are clearly very different,

96
00:06:50,500 --> 00:06:54,930
because it's very important not
to miss a legitimate email.

97
00:06:54,930 --> 00:06:59,930
It's okay to occasionally let a spam
email to come into your inbox.

98
00:06:59,930 --> 00:07:05,960
So the error of the first, missing a
legitimate email is very, is of high cost.

99
00:07:05,960 --> 00:07:08,670
It's a very serious mistake and

100
00:07:08,670 --> 00:07:13,240
classification error, classification
accuracy does not address this issue.

101
00:07:14,340 --> 00:07:16,950
There's also another problem
with imbalance to test set.

102
00:07:16,950 --> 00:07:22,883
Imagine there's a skew to test set where
most instances are category one and

103
00:07:22,883 --> 00:07:25,950
98% of instances are category one.

104
00:07:25,950 --> 00:07:26,900
Only 2% are in category two.

105
00:07:26,900 --> 00:07:31,400
In such a case, we can have a very
simple baseline that accurately performs

106
00:07:31,400 --> 00:07:32,520
very well and that baseline.

107
00:07:32,520 --> 00:07:35,370
Sign with similar,
I put all instances in the major category.

108
00:07:36,510 --> 00:07:39,450
That will get us 98%
accuracy in this case.

109
00:07:39,450 --> 00:07:43,760
It's going to be appearing to be
very effective, but in reality,

110
00:07:43,760 --> 00:07:45,580
this is obviously not a good result.

111
00:07:47,180 --> 00:07:51,550
And so, in general, when we use
classification accuracy as a measure,

112
00:07:51,550 --> 00:07:53,980
we want to ensure that
the causes of balance.

113
00:07:54,980 --> 00:07:57,340
And one above equal number of instances,
for

114
00:07:57,340 --> 00:08:02,860
example in each class the minority
categories or causes tend to be

115
00:08:02,860 --> 00:08:07,290
overlooked in the evaluation
of classification accuracy.

116
00:08:07,290 --> 00:08:11,595
So, to address these problems,
we of course would like to also evaluate

117
00:08:11,595 --> 00:08:14,550
the results in other ways and
in different ways.

118
00:08:14,550 --> 00:08:18,670
As I said, it's beneficial to look
at after multiple perspectives.

119
00:08:18,670 --> 00:08:22,310
So for example, we can look at
the perspective from each document

120
00:08:22,310 --> 00:08:25,350
as a perspective based on each document.

121
00:08:25,350 --> 00:08:28,689
So the question here is, how good
are the decisions on this document?

122
00:08:29,900 --> 00:08:35,670
Now, as in the general cases of all
decisions, we can think about four

123
00:08:35,670 --> 00:08:40,786
combinations of possibilities, depending
on whether the system has said yes and

124
00:08:40,786 --> 00:08:46,650
depending on whether the human has said it
correct or incorrect or said yes or no.

125
00:08:46,650 --> 00:08:53,660
And so the four combinations are first
when both the human systems said yes, and

126
00:08:53,660 --> 00:08:59,200
that's the true positives, when the system
says, yes, and it's after the positive.

127
00:08:59,200 --> 00:09:02,210
So, when the system says,
yes, it's a positive.

128
00:09:02,210 --> 00:09:05,420
But, when the human confirm
that it is indeed correct,

129
00:09:05,420 --> 00:09:06,870
that becomes a true positive.

130
00:09:07,920 --> 00:09:10,710
When the system says, yes,
but the human says, no,

131
00:09:10,710 --> 00:09:13,950
that's incorrect,
that's a false positive, have FP.

132
00:09:15,010 --> 00:09:20,000
And when the system says no, but the human
says yes, then it's a false negative.

133
00:09:20,000 --> 00:09:22,240
We missed one assignment.

134
00:09:22,240 --> 00:09:23,740
When both the system and

135
00:09:23,740 --> 00:09:28,890
human says no, then it's also correctly
to assume that's true negatives.

136
00:09:28,890 --> 00:09:33,800
All right, so
then we can have some measures to just

137
00:09:33,800 --> 00:09:38,160
better characterize the performance
by using these four numbers and

138
00:09:38,160 --> 00:09:40,610
so two popular measures are precision and
recall.

139
00:09:40,610 --> 00:09:45,480
And these were also proposed by
information retrieval researchers 1960s

140
00:09:45,480 --> 00:09:47,360
for evaluating search results, but

141
00:09:47,360 --> 00:09:51,080
now they have become standard measures,
use it everywhere.

142
00:09:51,080 --> 00:09:55,980
So when the system says yes, we can ask
the question, how many are correct?

143
00:09:55,980 --> 00:10:00,390
What's the percent of correct
decisions when the system says yes?

144
00:10:00,390 --> 00:10:02,320
That's called precision.

145
00:10:02,320 --> 00:10:06,560
It's true positive divided by all
the cases when the system says yes,

146
00:10:06,560 --> 00:10:09,690
all the positives.

147
00:10:09,690 --> 00:10:13,029
The other measure is called recall,
and this measures

148
00:10:14,200 --> 00:10:18,810
whether the document has all
the categories it should have.

149
00:10:18,810 --> 00:10:23,980
So in this case it's divide the true
positive by true positives and

150
00:10:23,980 --> 00:10:25,870
the false negatives.

151
00:10:25,870 --> 00:10:28,430
So these are all the cases where

152
00:10:28,430 --> 00:10:32,960
this human Says the document
should have this category.

153
00:10:32,960 --> 00:10:37,180
So this represents both categories
that it should have got, and

154
00:10:37,180 --> 00:10:40,480
so recall tells us whether
the system has actually indeed

155
00:10:40,480 --> 00:10:44,500
assigned all the categories that
it should have to this document.

156
00:10:46,000 --> 00:10:49,300
This gives us a detailed
view of the document,

157
00:10:49,300 --> 00:10:50,790
then we can aggregate them later.

158
00:10:52,060 --> 00:10:53,980
And if we're interested in some documents,
and

159
00:10:53,980 --> 00:10:59,750
this will tell us how well we did on
those documents, the subsets of them.

160
00:10:59,750 --> 00:11:02,260
It might be more interesting than others,
for example.

161
00:11:02,260 --> 00:11:05,580
And this allows us to analyze
errors in more detail as well.

162
00:11:05,580 --> 00:11:09,680
We can separate the documents of certain
characteristics from others, and

163
00:11:09,680 --> 00:11:10,700
then look at the errors.

164
00:11:10,700 --> 00:11:14,370
You might see a pattern A for
this kind of document, this long document.

165
00:11:14,370 --> 00:11:17,350
It doesn't as well for shock documents.

166
00:11:18,900 --> 00:11:22,760
And this gives you some insight for
inputting the method.

167
00:11:22,760 --> 00:11:25,830
Similarly, we can look at
the per-category evaluation.

168
00:11:25,830 --> 00:11:26,760
In this case,

169
00:11:26,760 --> 00:11:30,690
we're going to look at the how good are
the decisions on a particular category.

170
00:11:30,690 --> 00:11:34,580
As in the previous case we can
define precision and recall.

171
00:11:34,580 --> 00:11:38,740
And it would just basically answer the
questions from a different perspective.

172
00:11:39,820 --> 00:11:43,430
So when the system says yes,
how many are correct?

173
00:11:43,430 --> 00:11:48,580
That means looking at this category
to see if all the documents

174
00:11:48,580 --> 00:11:53,520
that are assigned with this category
are indeed in this category, right?

175
00:11:53,520 --> 00:11:56,630
And recall, would tell us,
has the category been actually assigned to

176
00:11:56,630 --> 00:11:58,750
all the documents That
should have this category.

177
00:12:00,730 --> 00:12:04,990
It's sometimes also useful to combine
precision and recall as one measure, and

178
00:12:04,990 --> 00:12:08,230
this is often done by using f measure.

179
00:12:08,230 --> 00:12:10,410
And this is just a harmonic
mean of precision.

180
00:12:10,410 --> 00:12:13,410
Precision and
recall defined on this slide.

181
00:12:13,410 --> 00:12:18,640
And it's also controlled
by a parameter beta to

182
00:12:20,200 --> 00:12:23,680
indicate whether precision is
more important or recall is more.

183
00:12:23,680 --> 00:12:28,260
When beta is set to 1,
we have measure called F1, and

184
00:12:28,260 --> 00:12:33,120
in this case, we just take equal
weight upon both procedure and recall.

185
00:12:34,710 --> 00:12:38,890
F1 is very often used as a measure for
categorization.

186
00:12:39,960 --> 00:12:44,520
Now, as in all cases, when we combine
results, you always should think about

187
00:12:44,520 --> 00:12:48,160
the best way of combining them, so in this
case I don't know if you have thought

188
00:12:48,160 --> 00:12:52,810
about it and we could have combined
them just with arithmetic mean, right.

189
00:12:52,810 --> 00:12:56,520
So that would still give us
the same range of values, but

190
00:12:56,520 --> 00:13:00,460
obviously there's a reason why we didn't
do that and why f1 is more popular,

191
00:13:00,460 --> 00:13:04,070
and it's actually useful
to think about difference.

192
00:13:04,070 --> 00:13:08,610
And we think about that, you'll see
that there is indeed some difference and

193
00:13:08,610 --> 00:13:13,480
some undesirable property
of this arithmatic.

194
00:13:13,480 --> 00:13:17,640
Basically, it will be obvious
to you if you think about a case

195
00:13:17,640 --> 00:13:21,932
when the system says yes for
all the category and document pairs.

196
00:13:21,932 --> 00:13:26,350
And then try the compute the precision and
recall in that case.

197
00:13:26,350 --> 00:13:27,400
And see what would happen.

198
00:13:28,410 --> 00:13:32,956
And basically, this kind of measure,

199
00:13:32,956 --> 00:13:37,776
the arithmetic mean, is not going to be as

200
00:13:37,776 --> 00:13:43,563
reasonable as F1 minus one
[INAUDIBLE] trade off,

201
00:13:43,563 --> 00:13:47,443
so that the two values are equal.

202
00:13:47,443 --> 00:13:53,443
There is an extreme case where you have
0 for one letter and one for the other.

203
00:13:53,443 --> 00:13:58,883
Then F1 will be low, but
the mean would still be reasonably high.

204
00:14:01,123 --> 00:14:11,123
[MUSIC]