1
00:00:00,025 --> 00:00:06,885
[SOUND]
>> This

2
00:00:06,885 --> 00:00:11,190
lecture is about topic mining and
analysis.

3
00:00:11,190 --> 00:00:14,270
We're going to talk about its
motivation and task definition.

4
00:00:17,780 --> 00:00:22,630
In this lecture we're going to talk
about different kind of mining task.

5
00:00:23,770 --> 00:00:28,310
As you see on this road map,
we have just covered

6
00:00:28,310 --> 00:00:33,190
mining knowledge about language,
namely discovery of

7
00:00:33,190 --> 00:00:37,987
word associations such as paradigmatic and
relations and syntagmatic relations.

8
00:00:39,190 --> 00:00:43,100
Now, starting from this lecture, we're
going to talk about mining another kind of

9
00:00:43,100 --> 00:00:47,570
knowledge, which is content mining, and

10
00:00:47,570 --> 00:00:55,031
trying to discover knowledge about
the main topics in the text.

11
00:00:56,140 --> 00:00:58,810
And we call that topic mining and
analysis.

12
00:00:59,920 --> 00:01:04,350
In this lecture, we're going to talk about
its motivation and the task definition.

13
00:01:04,350 --> 00:01:08,260
So first of all,
let's look at the concept of topic.

14
00:01:08,260 --> 00:01:12,600
So topic is something that we
all understand, I think, but

15
00:01:12,600 --> 00:01:15,840
it's actually not that
easy to formally define.

16
00:01:15,840 --> 00:01:20,420
Roughly speaking, topic is the main
idea discussed in text data.

17
00:01:20,420 --> 00:01:25,860
And you can think of this as a theme or
subject of a discussion or conversation.

18
00:01:25,860 --> 00:01:28,420
It can also have different granularities.

19
00:01:28,420 --> 00:01:31,240
For example,
we can talk about the topic of a sentence.

20
00:01:31,240 --> 00:01:34,800
A topic of article,
aa topic of paragraph or

21
00:01:34,800 --> 00:01:40,540
the topic of all the research articles
in the research library, right,

22
00:01:40,540 --> 00:01:45,629
so different grand narratives of topics
obviously have different applications.

23
00:01:46,760 --> 00:01:51,628
Indeed, there are many applications that
require discovery of topics in text, and

24
00:01:51,628 --> 00:01:52,980
they're analyzed then.

25
00:01:52,980 --> 00:01:54,300
Here are some examples.

26
00:01:54,300 --> 00:01:58,280
For example, we might be interested
in knowing about what are Twitter

27
00:01:58,280 --> 00:02:00,470
users are talking about today?

28
00:02:00,470 --> 00:02:03,600
Are they talking about NBA sports, or

29
00:02:03,600 --> 00:02:08,540
are they talking about some
international events, etc.?

30
00:02:08,540 --> 00:02:12,970
Or we are interested in
knowing about research topics.

31
00:02:12,970 --> 00:02:17,090
For example, one might be interested in
knowing what are the current research

32
00:02:17,090 --> 00:02:21,840
topics in data mining, and how are they
different from those five years ago?

33
00:02:21,840 --> 00:02:26,820
Now this involves discovery of topics
in data mining literatures and

34
00:02:26,820 --> 00:02:32,910
also we want to discover topics in
today's literature and those in the past.

35
00:02:32,910 --> 00:02:34,690
And then we can make a comparison.

36
00:02:34,690 --> 00:02:38,400
We might also be also interested in
knowing what do people like about

37
00:02:38,400 --> 00:02:43,710
some products like the iPhone 6,
and what do they dislike?

38
00:02:43,710 --> 00:02:48,360
And this involves discovering
topics in positive opinions about

39
00:02:48,360 --> 00:02:52,470
iPhone 6 and
also negative reviews about it.

40
00:02:52,470 --> 00:02:56,810
Or perhaps we're interested in knowing
what are the major topics debated in 2012

41
00:02:56,810 --> 00:02:58,110
presidential election?

42
00:02:59,780 --> 00:03:04,800
And all these have to do with discovering
topics in text and analyzing them,

43
00:03:04,800 --> 00:03:08,680
and we're going to talk about a lot
of techniques for doing this.

44
00:03:08,680 --> 00:03:12,920
In general we can view a topic as
some knowledge about the world.

45
00:03:12,920 --> 00:03:17,830
So from text data we expect to
discover a number of topics, and

46
00:03:17,830 --> 00:03:22,650
then these topics generally provide
a description about the world.

47
00:03:22,650 --> 00:03:25,690
And it tells us something about the world.

48
00:03:25,690 --> 00:03:28,230
About a product, about a person etc.

49
00:03:29,350 --> 00:03:32,390
Now when we have some non-text data,

50
00:03:32,390 --> 00:03:36,420
then we can have more context for
analyzing the topics.

51
00:03:36,420 --> 00:03:41,620
For example, we might know the time
associated with the text data, or

52
00:03:41,620 --> 00:03:47,110
locations where the text
data were produced,

53
00:03:47,110 --> 00:03:52,945
or the authors of the text, or
the sources of the text, etc.

54
00:03:52,945 --> 00:03:54,400
All such meta data, or

55
00:03:54,400 --> 00:03:59,610
context variables can be associated
with the topics that we discover, and

56
00:03:59,610 --> 00:04:05,340
then we can use these context variables
help us analyze patterns of topics.

57
00:04:05,340 --> 00:04:09,320
For example, looking at topics over time,
we would be able to discover

58
00:04:09,320 --> 00:04:14,290
whether there's a trending topic, or
some topics might be fading away.

59
00:04:15,620 --> 00:04:18,950
Soon you are looking at topics
in different locations.

60
00:04:18,950 --> 00:04:24,185
We might know some insights about
people's opinions in different locations.

61
00:04:26,150 --> 00:04:29,900
So that's why mining
topics is very important.

62
00:04:29,900 --> 00:04:34,540
Now, let's look at the tasks
of topic mining and analysis.

63
00:04:34,540 --> 00:04:39,380
In general, it would involve first
discovering a lot of topics, in this case,

64
00:04:39,380 --> 00:04:40,810
k topics.

65
00:04:40,810 --> 00:04:45,430
And then we also would like to know, which
topics are covered in which documents,

66
00:04:45,430 --> 00:04:46,600
to what extent.

67
00:04:46,600 --> 00:04:52,970
So for example, in document one, we
might see that Topic 1 is covered a lot,

68
00:04:52,970 --> 00:04:57,390
Topic 2 and
Topic k are covered with a small portion.

69
00:04:58,890 --> 00:05:00,712
And other topics,
perhaps, are not covered.

70
00:05:00,712 --> 00:05:06,778
Document two, on the other hand,
covered Topic 2 very well,

71
00:05:06,778 --> 00:05:10,553
but it did not cover Topic 1 at all, and

72
00:05:10,553 --> 00:05:15,873
it also covers Topic k to some extent,
etc., right?

73
00:05:15,873 --> 00:05:19,995
So now you can see there
are generally two different tasks, or

74
00:05:19,995 --> 00:05:25,760
sub-tasks, the first is to discover k
topics from a collection of text laid out.

75
00:05:25,760 --> 00:05:27,140
What are these k topics?

76
00:05:27,140 --> 00:05:28,920
Okay, major topics in the text they are.

77
00:05:28,920 --> 00:05:33,180
The second task is to figure out
which documents cover which topics

78
00:05:33,180 --> 00:05:34,430
to what extent.

79
00:05:34,430 --> 00:05:37,810
So more formally,
we can define the problem as follows.

80
00:05:37,810 --> 00:05:42,365
First, we have, as input,
a collection of N text documents.

81
00:05:42,365 --> 00:05:47,050
Here we can denote the text
collection as C, and

82
00:05:47,050 --> 00:05:51,740
denote text article as d i.

83
00:05:51,740 --> 00:05:56,700
And, we generally also need to have
as input the number of topics, k.

84
00:05:56,700 --> 00:06:01,730
But there may be techniques that can
automatically suggest a number of topics.

85
00:06:01,730 --> 00:06:06,735
But in the techniques that we will
discuss, which are also the most useful

86
00:06:06,735 --> 00:06:12,340
techniques, we often need to
specify a number of topics.

87
00:06:14,580 --> 00:06:19,860
Now the output would then be the k
topics that we would like to discover,

88
00:06:19,860 --> 00:06:23,210
in order as theta sub
one through theta sub k.

89
00:06:24,540 --> 00:06:29,820
Also we want to generate the coverage of
topics in each document of d sub i And

90
00:06:29,820 --> 00:06:32,518
this is denoted by pi sub i j.

91
00:06:33,562 --> 00:06:38,073
And pi sub ij is the probability
of document d sub i

92
00:06:38,073 --> 00:06:41,290
covering topic theta sub j.

93
00:06:41,290 --> 00:06:45,450
So obviously for each document, we have
a set of such values to indicate to

94
00:06:45,450 --> 00:06:47,830
what extent the document covers,
each topic.

95
00:06:48,930 --> 00:06:53,610
And we can assume that these
probabilities sum to one.

96
00:06:53,610 --> 00:06:57,000
Because a document won't be able to cover

97
00:06:57,000 --> 00:07:02,520
other topics outside of the topics
that we discussed, that we discovered.

98
00:07:02,520 --> 00:07:08,170
So now, the question is, how do we define
theta sub i, how do we define the topic?

99
00:07:08,170 --> 00:07:11,500
Now this problem has not
been completely defined

100
00:07:11,500 --> 00:07:15,180
until we define what is exactly theta.

101
00:07:16,970 --> 00:07:19,381
So in the next few lectures,

102
00:07:19,381 --> 00:07:24,211
we're going to talk about
different ways to define theta.

103
00:07:24,211 --> 00:07:34,211
[MUSIC]

