1
00:00:00,025 --> 00:00:04,546
[SOUND] This lecture is

2
00:00:04,546 --> 00:00:10,323
about the word association

3
00:00:10,323 --> 00:00:15,100
mining and analysis.

4
00:00:15,100 --> 00:00:19,884
In this lecture,
we're going to talk about how to mine

5
00:00:19,884 --> 00:00:22,902
associations of words from text.

6
00:00:22,902 --> 00:00:27,900
Now this is an example of knowledge
about the natural language that

7
00:00:27,900 --> 00:00:29,960
we can mine from text data.

8
00:00:33,942 --> 00:00:35,090
Here's the outline.

9
00:00:35,090 --> 00:00:39,828
We're going to first talk about
what is word association and

10
00:00:39,828 --> 00:00:45,100
then explain why discovering such
relations is useful and finally

11
00:00:45,100 --> 00:00:50,070
we're going to talk about some general
ideas about how to mine word associations.

12
00:00:50,070 --> 00:00:55,209
In general there are two word
relations and these are quite basic.

13
00:00:56,680 --> 00:00:58,680
One is called a paradigmatic relation.

14
00:00:58,680 --> 00:01:03,000
The other is syntagmatic relation.

15
00:01:03,000 --> 00:01:07,780
A and B have paradigmatic relation

16
00:01:07,780 --> 00:01:11,700
if they can be substituted for each other.

17
00:01:11,700 --> 00:01:17,910
That means the two words that
have paradigmatic relation

18
00:01:17,910 --> 00:01:23,130
would be in the same semantic class,
or syntactic class.

19
00:01:23,130 --> 00:01:26,910
And we can in general
replace one by the other

20
00:01:26,910 --> 00:01:30,310
without affecting
the understanding of the sentence.

21
00:01:30,310 --> 00:01:33,810
That means we would still
have a valid sentence.

22
00:01:33,810 --> 00:01:41,530
For example, cat and dog, these two
words have a paradigmatic relation

23
00:01:41,530 --> 00:01:47,710
because they are in
the same class of animal.

24
00:01:47,710 --> 00:01:51,827
And in general,
if you replace cat with dog in a sentence,

25
00:01:51,827 --> 00:01:56,880
the sentence would still be a valid
sentence that you can make sense of.

26
00:01:58,320 --> 00:02:01,990
Similarly Monday and
Tuesday have paradigmatical relation.

27
00:02:04,930 --> 00:02:09,390
The second kind of relation is
called syntagmatical relation.

28
00:02:10,610 --> 00:02:17,200
In this case, the two words that have this
relation, can be combined with each other.

29
00:02:17,200 --> 00:02:22,190
So A and B have syntagmatic relation if
they can be combined with each other in

30
00:02:22,190 --> 00:02:29,500
a sentence, that means these two
words are semantically related.

31
00:02:30,720 --> 00:02:36,830
So for example, cat and sit are related
because a cat can sit somewhere.

32
00:02:38,060 --> 00:02:43,870
Similarly, car and
drive are related semantically and

33
00:02:43,870 --> 00:02:47,550
they can be combined with
each other to convey meaning.

34
00:02:47,550 --> 00:02:54,150
However, in general, we can not
replace cat with sit in a sentence or

35
00:02:54,150 --> 00:02:59,590
car with drive in the sentence
to still get a valid sentence,

36
00:02:59,590 --> 00:03:03,950
meaning that if we do that, the sentence
will become somewhat meaningless.

37
00:03:03,950 --> 00:03:10,135
So this is different from
paradigmatic relation.

38
00:03:10,135 --> 00:03:15,875
And these two relations are in fact so
fundamental that they can be

39
00:03:17,365 --> 00:03:24,180
generalized to capture basic relations
between units in arbitrary sequences.

40
00:03:24,180 --> 00:03:27,880
And definitely they can be
generalized to describe

41
00:03:27,880 --> 00:03:31,630
relations of any items in a language.

42
00:03:31,630 --> 00:03:36,620
So, A and B don't have to be words and
they can be phrases, for example.

43
00:03:37,960 --> 00:03:44,710
And they can even be more complex
phrases than just a non-phrase.

44
00:03:44,710 --> 00:03:48,820
If you think about the general
problem of the sequence mining

45
00:03:48,820 --> 00:03:53,066
then we can think about the units
being and the sequence data.

46
00:03:53,066 --> 00:03:58,980
Then we think of paradigmatic
relation as relations that

47
00:03:58,980 --> 00:04:05,890
are applied to units that tend to occur
in a singular locations in a sentence,

48
00:04:05,890 --> 00:04:11,660
or in a sequence of data
elements in general.

49
00:04:11,660 --> 00:04:20,980
So they occur in similar locations
relative to the neighbors in the sequence.

50
00:04:20,980 --> 00:04:25,415
Syntagmatical relation on
the other hand is related to

51
00:04:25,415 --> 00:04:30,210
co-occurrent elements that tend
to show up in the same sequence.

52
00:04:33,150 --> 00:04:38,470
So these two are complimentary and
are basic relations of words.

53
00:04:38,470 --> 00:04:42,810
And we're interested in discovering
them automatically from text data.

54
00:04:42,810 --> 00:04:46,420
Discovering such worded
relations has many applications.

55
00:04:47,480 --> 00:04:52,920
First, such relations can be directly
useful for improving accuracy of many NLP

56
00:04:52,920 --> 00:04:58,880
tasks, and this is because this is part
of our knowledge about a language.

57
00:04:58,880 --> 00:05:02,440
So if you know these two words
are synonyms, for example,

58
00:05:02,440 --> 00:05:04,970
and then you can help a lot of tasks.

59
00:05:05,980 --> 00:05:10,970
And grammar learning can be also
done by using such techniques.

60
00:05:10,970 --> 00:05:15,130
Because if we can learn
paradigmatic relations,

61
00:05:15,130 --> 00:05:20,000
then we form classes of words,
syntactic classes for example.

62
00:05:20,000 --> 00:05:25,630
And if we learn syntagmatic relations,
then we would be able to know

63
00:05:25,630 --> 00:05:32,400
the rules for putting together a larger
expression based on component expressions.

64
00:05:32,400 --> 00:05:37,390
So we learn the structure and
what can go with what else.

65
00:05:39,855 --> 00:05:43,070
Word relations can be also very useful for

66
00:05:43,070 --> 00:05:46,580
many applications in text retrieval and
mining.

67
00:05:46,580 --> 00:05:50,520
For example, in search and
text retrieval, we can use word

68
00:05:50,520 --> 00:05:55,930
associations to modify a query,
and this can be used to

69
00:05:55,930 --> 00:06:00,480
introduce additional related words into
a query and make the query more effective.

70
00:06:01,590 --> 00:06:03,390
It's often called a query expansion.

71
00:06:05,290 --> 00:06:10,030
Or you can use related words to
suggest related queries to the user

72
00:06:10,030 --> 00:06:11,660
to explore the information space.

73
00:06:12,740 --> 00:06:15,610
Another application is to
use word associations to

74
00:06:15,610 --> 00:06:19,790
automatically construct the top
of the map for browsing.

75
00:06:19,790 --> 00:06:24,540
We can have words as nodes and
associations as edges.

76
00:06:24,540 --> 00:06:27,930
A user could navigate from
one word to another to

77
00:06:28,990 --> 00:06:31,180
find information in the information space.

78
00:06:33,620 --> 00:06:40,620
Finally, such word associations can also
be used to compare and summarize opinions.

79
00:06:40,620 --> 00:06:45,680
For example, we might be interested
in understanding positive and

80
00:06:45,680 --> 00:06:48,620
negative opinions about the iPhone 6.

81
00:06:48,620 --> 00:06:55,180
In order to do that, we can look at what
words are most strongly associated with

82
00:06:55,180 --> 00:07:01,630
a feature word like battery in
positive versus negative reviews.

83
00:07:01,630 --> 00:07:05,147
Such a syntagmatical
relations would help us

84
00:07:05,147 --> 00:07:08,854
show the detailed opinions
about the product.

85
00:07:16,696 --> 00:07:20,837
So, how can we discover such
associations automatically?

86
00:07:20,837 --> 00:07:24,450
Now, here are some intuitions
about how to do that.

87
00:07:24,450 --> 00:07:27,479
Now let's first look at
the paradigmatic relation.

88
00:07:29,080 --> 00:07:32,940
Here we essentially can take
advantage of similar context.

89
00:07:34,150 --> 00:07:38,440
So here you see some simple
sentences about cat and dog.

90
00:07:38,440 --> 00:07:43,416
You can see they generally
occur in similar context,

91
00:07:43,416 --> 00:07:48,390
and that after all is the definition
of paradigmatic relation.

92
00:07:49,540 --> 00:07:54,510
On the right side you can kind
of see I extracted expressly

93
00:07:54,510 --> 00:07:59,090
the context of cat and
dog from this small sample of text data.

94
00:08:00,640 --> 00:08:05,230
I've taken away cat and
dog from these sentences, so

95
00:08:05,230 --> 00:08:07,280
that you can see just the context.

96
00:08:08,810 --> 00:08:12,660
Now, of course we can have different
perspectives to look at the context.

97
00:08:13,810 --> 00:08:19,528
For example, we can look at
what words occur in the left

98
00:08:19,528 --> 00:08:24,222
part of this context.

99
00:08:24,222 --> 00:08:28,000
So we can call this left context.

100
00:08:28,000 --> 00:08:34,800
What words occur before we see cat or dog?

101
00:08:34,800 --> 00:08:39,910
So, you can see in this case, clearly
dog and cat have similar left context.

102
00:08:41,810 --> 00:08:47,860
You generally say his cat or my cat and
you say also, my dog and his dog.

103
00:08:47,860 --> 00:08:52,290
So that makes them similar
in the left context.

104
00:08:53,660 --> 00:08:58,880
Similarly, if you look at the words
that occur after cat and dog,

105
00:08:58,880 --> 00:09:03,970
which we can call right context,
they are also very similar in this case.

106
00:09:03,970 --> 00:09:07,490
Of course, it's an extreme case,
where you only see eats.

107
00:09:08,670 --> 00:09:12,883
And in general,
you'll see many other words, of course,

108
00:09:12,883 --> 00:09:15,170
that can't follow cat and dog.

109
00:09:17,830 --> 00:09:21,700
You can also even look
at the general context.

110
00:09:21,700 --> 00:09:24,690
And that might include all
the words in the sentence or

111
00:09:24,690 --> 00:09:26,640
in sentences around this word.

112
00:09:27,658 --> 00:09:34,300
And even in the general context, you also
see similarity between the two words.

113
00:09:35,400 --> 00:09:41,480
So this was just a suggestion
that we can discover paradigmatic

114
00:09:41,480 --> 00:09:47,000
relation by looking at
the similarity of context of words.

115
00:09:47,000 --> 00:09:50,900
So, for example,
if we think about the following questions.

116
00:09:50,900 --> 00:09:54,760
How similar are context of cat and
context of dog?

117
00:09:56,240 --> 00:10:01,630
In contrast how similar are context
of cat and context of computer?

118
00:10:02,660 --> 00:10:07,610
Now, intuitively,
we're to imagine the context of cat and

119
00:10:07,610 --> 00:10:11,030
the context of dog would
be more similar than

120
00:10:11,030 --> 00:10:16,550
the context of cat and
context of the computer.

121
00:10:16,550 --> 00:10:20,680
That means, in the first case
the similarity value would be high,

122
00:10:21,910 --> 00:10:25,940
between the context of cat and
dog, where as in the second,

123
00:10:25,940 --> 00:10:30,248
the similarity between context of cat and
computer would be low

124
00:10:30,248 --> 00:10:35,750
because they all not having a paradigmatic

125
00:10:35,750 --> 00:10:40,550
relationship and imagine what words
occur after computer in general.

126
00:10:40,550 --> 00:10:44,900
It would be very different from
what words occur after cat.

127
00:10:46,620 --> 00:10:50,340
So this is the basic idea of what
this covering, paradigmatic relation.

128
00:10:52,040 --> 00:10:54,180
What about the syntagmatic relation?

129
00:10:54,180 --> 00:10:58,550
Well, here we're going to explore
the correlated occurrences,

130
00:10:58,550 --> 00:11:02,430
again based on the definition
of syntagmatic relation.

131
00:11:03,990 --> 00:11:05,600
Here you see the same sample of text.

132
00:11:06,640 --> 00:11:10,710
But here we're interested in knowing
what other words are correlated

133
00:11:10,710 --> 00:11:14,780
with the verb eats and
what words can go with eats.

134
00:11:16,380 --> 00:11:20,880
And if you look at the right
side of this slide and

135
00:11:20,880 --> 00:11:25,245
you see,
I've taken away the two words around eats.

136
00:11:27,110 --> 00:11:30,140
I've taken away the word to its left and

137
00:11:30,140 --> 00:11:33,970
also the word to its
right in each sentence.

138
00:11:35,340 --> 00:11:41,900
And then we ask the question, what words
tend to occur to the left of eats?

139
00:11:43,650 --> 00:11:47,960
And what words tend to
occur to the right of eats?

140
00:11:49,560 --> 00:11:54,997
Now thinking about this question
would help us discover syntagmatic

141
00:11:54,997 --> 00:12:00,830
relations because syntagmatic relations
essentially captures such correlations.

142
00:12:03,070 --> 00:12:07,290
So the important question to ask for
syntagmatical relation is,

143
00:12:07,290 --> 00:12:14,570
whenever eats occurs,
what other words also tend to occur?

144
00:12:16,180 --> 00:12:19,120
So the question here has
to do with whether there

145
00:12:19,120 --> 00:12:23,940
are some other words that tend
to co-occur together with each.

146
00:12:23,940 --> 00:12:28,240
Meaning that whenever you see eats
you tend to see the other words.

147
00:12:29,620 --> 00:12:34,660
And if you don't see eats, probably,
you don't see other words often either.

148
00:12:36,560 --> 00:12:40,210
So this intuition can help
discover syntagmatic relations.

149
00:12:41,530 --> 00:12:43,200
Now again, consider example.

150
00:12:44,210 --> 00:12:48,170
How helpful is occurrence of eats for
predicting occurrence of meat?

151
00:12:49,870 --> 00:12:53,056
Right.
All right, so knowing whether eats occurs

152
00:12:53,056 --> 00:12:58,930
in a sentence would generally help us
predict whether meat also occurs indeed.

153
00:12:58,930 --> 00:13:01,801
And if we see eats occur in the sentence,
and

154
00:13:01,801 --> 00:13:05,770
that should increase the chance
that meat would also occur.

155
00:13:08,490 --> 00:13:12,150
In contrast,
if you look at the question in the bottom,

156
00:13:12,150 --> 00:13:15,710
how helpful is the occurrence of eats for
predicting of occurrence of text?

157
00:13:17,330 --> 00:13:20,270
Because eats and
text are not really related, so

158
00:13:20,270 --> 00:13:24,840
knowing whether eats occurred
in the sentence doesn't

159
00:13:24,840 --> 00:13:30,140
really help us predict the weather,
text also occurs in the sentence.

160
00:13:30,140 --> 00:13:34,100
So this is in contrast to
the question about eats and meat.

161
00:13:35,550 --> 00:13:38,790
This also helps explain that intuition

162
00:13:38,790 --> 00:13:43,100
behind the methods of what
discovering syntagmatic relations.

163
00:13:43,100 --> 00:13:49,090
Mainly we need to capture the correlation
between the occurrences of two words.

164
00:13:50,440 --> 00:13:52,860
So to summarize the general ideas for

165
00:13:52,860 --> 00:13:55,810
discovering word associations
are the following.

166
00:13:56,880 --> 00:14:02,240
For paradigmatic relation,
we present each word by its context.

167
00:14:02,240 --> 00:14:04,830
And then compute its context similarity.

168
00:14:04,830 --> 00:14:09,030
We're going to assume the words
that have high context similarity

169
00:14:09,030 --> 00:14:12,260
to have paradigmatic relation.

170
00:14:14,640 --> 00:14:19,970
For syntagmatic relation, we will count
how many times two words occur together

171
00:14:19,970 --> 00:14:25,180
in a context, which can be a sentence,
a paragraph, or a document even.

172
00:14:25,180 --> 00:14:28,180
And we're going to compare

173
00:14:28,180 --> 00:14:31,660
their co-occurrences with
their individual occurrences.

174
00:14:33,280 --> 00:14:36,660
We're going to assume words
with high co-occurrences but

175
00:14:36,660 --> 00:14:42,335
relatively low individual occurrences
to have syntagmatic relations

176
00:14:42,335 --> 00:14:46,581
because they attempt to occur together and
they don't usually occur alone.

177
00:14:46,581 --> 00:14:51,635
Note that the paradigmatic relation and
the syntagmatic relation

178
00:14:51,635 --> 00:14:57,065
are actually closely related
in that paradigmatically

179
00:14:57,065 --> 00:15:02,810
related words tend to have syntagmatic
relation with the same word.

180
00:15:02,810 --> 00:15:05,420
They tend to be associated
with the same word, and

181
00:15:05,420 --> 00:15:10,870
that suggests that we can also do join
the discovery of the two relations.

182
00:15:10,870 --> 00:15:15,190
So these general ideas can be
implemented in many different ways.

183
00:15:15,190 --> 00:15:19,129
And the course won't cover all of them,
but

184
00:15:19,129 --> 00:15:24,774
we will cover at least some of
the methods that are effective for

185
00:15:24,774 --> 00:15:27,669
discovering these relations.

186
00:15:27,669 --> 00:15:37,669
[MUSIC]

